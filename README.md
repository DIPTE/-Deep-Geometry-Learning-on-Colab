# Deep-Geometry-Learning-Paper
*  :smile:  View-Based
*  :laughing: Volume-Based
*  :smiley: Point Cloud-Based
*  :wink: Mesh-Based
*  :yum: Octree-Based
*  :stuck_out_tongue_closed_eyes: Fusion-Based
*  :joy: Datasets
<h1> 
 
```diff 
- View-Based
```

</h1>

---
## 2015
- [[ICCV](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Su_Multi-View_Convolutional_Neural_ICCV_2015_paper.pdf)] Multi-view convolutional neural networks for 3D shape recognition. [[tensorflow](https://github.com/ace19-dev/mvcnn-tf)][[pytorch](https://github.com/RBirkeland/MVCNN-PyTorch)] [__`Classification.`__ __`Retrieval.`__ ] :fire: :star:
- [[IEEE SIGNAL PROCESSING LETTERS](https://ieeexplore.ieee.org/document/7273863)] DeepPano: deep panoramic representation for 3-D shape recognition. [__`Classification.`__] 
---
## 2016
- [[CVPR](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Bai_GIFT_A_Real-Time_CVPR_2016_paper.pdf)] GIFT: A Real-time and Scalable 3D Shape Search Engine.  [__`Retrieval.`__] 
- [[ECCV](https://link.springer.com/chapter/10.1007/978-3-319-46466-4_14)] Deep learning 3D shape surfaces using geometry images. [__`Classification.`__ __`Retrieval.`__] 
- [[CVPR](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Johns_Pairwise_Decomposition_of_CVPR_2016_paper.pdf)] Pairwise decomposition of image sequences for active multi-view recognition.  [__`Classification.`__ __`Retrieval.`__] 
- [[CVPR](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Qi_Volumetric_and_Multi-View_CVPR_2016_paper.pdf)] Volumetric and multi-view CNNs for object classification on 3D data. [[lua](https://github.com/charlesq34/3dcnn.torch)] [__`Classification.`__ __`Retrieval.`__] 
- [[arXiv](https://arxiv.org/abs/1607.05695)] FusionNet: 3D object classification using multiple data representations. [__`Classification.`__] 
---
## 2017
- [[BMVC](http://www.bmva.org/bmvc/2017/papers/paper064/paper064.pdf)] Dominant set clustering and pooling for multi-view 3D object recognition. [[MATLAB](https://github.com/fate3439/dscnn)] [__`Classification.`__] 
- [[IGTA](https://link.springer.com/chapter/10.1007%2F978-981-10-7389-2_20)] Boosting multi-view convolutional neural networks for 3D object recognition via view saliency. [__`Classification.`__] 
- [[3DOR](https://diglib.eg.org/handle/10.2312/3dor20171045)] Exploiting the PANORAMA Representation for Convolutional Neural Network Classification and Retrieval. [__`Classification.`__ __`Retrieval.`__] 
---
## 2018
- [[IEEE TRANSACTION ON MULTIMEDIA](https://ieeexplore.ieee.org/document/8490588/)] Learning Multi-view Representation with LSTM for 3D Shape Recognition and Retrieval. [__`Classification.`__ __`Retrieval.`__] 
- [[IEEE Transactions on Image Processing](https://ieeexplore.ieee.org/document/8453813/)] SeqViews2SeqLabels: Learning 3D Global Features via Aggregating Sequential Views by RNN with Attention. [__`Classification.`__ __`Retrieval.`__] 
- [[CVPR](http://openaccess.thecvf.com/content_cvpr_2018/papers/Feng_GVCNN_Group-View_Convolutional_CVPR_2018_paper.pdf)] GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition. [[tensorflow](https://github.com/ace19-dev/gvcnn-tf)] [[pytorch](https://github.com/waxnkw/gvcnn-pytorch)][__`Classification.`__ __`Retrieval.`__] :fire: :star:
- [[CVPR](http://openaccess.thecvf.com/content_cvpr_2018/papers/Kanezaki_RotationNet_Joint_Object_CVPR_2018_paper.pdf)] Rotationnet: Joint object categorization and pose estimation using multiviews from unsupervised viewpoints. [[tensorflow](https://github.com/kanezaki/rotationnet)]  [[pytorch](https://github.com/kanezaki/pytorch-rotationnet)][__`Classification.`__ __`Retrieval.`__] :fire: :star:
- [[CVPR](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Multi-View_Harmonized_Bilinear_CVPR_2018_paper.pdf)] Multi-view harmonized bilinear network for 3d object recognition. [[pytorch](https://github.com/LiyuanLacfo/MHBNN-PyTorch)] [__`Classification.`__] 
---
## 2019
- [[IEEE Transactions on Image Processing](https://ieeexplore.ieee.org/document/8666059)] 3D2SeqViews: Aggregating Sequential Views for 3D Global Feature Learning by CNN with Hierarchical Attention Aggregation . [__`Classification.`__ __`Retrieval.`__] 
- [[AAAI](https://www.aaai.org/ojs/index.php/AAAI/article/view/4869)] MLVCNN: Multi-Loop-View Convolutional Neural Network for 3D Shape Retrieval. [__`Classification.`__ __`Retrieval.`__] 
- [[AAAI](https://www.aaai.org/ojs/index.php/AAAI/article/view/4868)] DeepCCFV: Camera Constraint-Free Multi-View Convolutional Neural Network for 3D Object Retrieval. [__`Classification.`__ __`Retrieval.`__] 
- [[CVPR](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Learning_With_Batch-Wise_Optimal_Transport_Loss_for_3D_Shape_Recognition_CVPR_2019_paper.pdf)] Learning with Batch-wise Optimal Transport Loss for 3D Shape Recognition. [[pytorch](https://github.com/IAAI-CVResearchGroup/BOT-Learning/tree/master/3D-Shape-Recognition)] [__`Classification.`__ __`Retrieval.`__] 
- [[AAAI](https://www.aaai.org/ojs/index.php/AAAI/article/view/4890)] Angular Triplet-Center Loss for Multi-View 3D Shape Retrieval.[__`Classification.`__ __`Retrieval.`__] 
- [[IJCAI](https://www.ijcai.org/Proceedings/2019/118)] Rethinking Loss Design for Large-scale 3D Shape Retrieval.[__`Classification.`__ __`Retrieval.`__] 
- [[IJCAI](https://www.ijcai.org/Proceedings/2019/108)] Parts4Feature: Learning 3D Global Features from Generally Semantic Parts in Multiple Views.[__`Classification.`__ __`Retrieval.`__] 
- [[IJCAI](https://www.ijcai.org/Proceedings/2019/107)] 3DViewGraph: Learning Global Features for 3D Shapes from A Graph of Unordered Views with Attention.[__`Classification.`__ __`Retrieval.`__] 
- [[AAAI](https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/4852)] View Inter-Prediction GAN: Unsupervised Representation Learning for 3D Shapes by Learning Global Shape Memories to Support Local View Predictions.[__`Classification.`__ __`Retrieval.`__] 
- [[ICCV](http://openaccess.thecvf.com/content_ICCV_2019/papers/He_View_N-Gram_Network_for_3D_Object_Retrieval_ICCV_2019_paper.pdf)] View N-gram Network for 3D Object Retrieval. [__`Classification.`__ __`Retrieval.`__] 
---
## 2020
- [[CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wei_View-GCN_View-Based_Graph_Convolutional_Network_for_3D_Shape_Analysis_CVPR_2020_paper.pdf)] View-GCN: View-based Graph Convolutional Network for 3D Shape Analysis.   [[pytorch](https://github.com/weixmath/view-GCN)][__`Classification.`__ __`Retrieval.`__] :fire: :star:
---
<h1> 
 
```diff
- Datasets
```

</h1>

- [[KITTI](http://www.cvlibs.net/datasets/kitti/)] The KITTI Vision Benchmark Suite. 
- [[ModelNet](http://modelnet.cs.princeton.edu/)] The Princeton ModelNet .
- [[ShapeNet](https://www.shapenet.org/)]  A collaborative dataset between researchers at Princeton, Stanford and TTIC.
- [[PartNet](https://shapenet.org/download/parts)] The PartNet dataset provides fine grained part annotation of objects in ShapeNetCore. 
- [[PartNet](http://kevinkaixu.net/projects/partnet.html)] PartNet benchmark from Nanjing University and National University of Defense Technology. 
- [[S3DIS](http://buildingparser.stanford.edu/dataset.html#Download)] The Stanford Large-Scale 3D Indoor Spaces Dataset. 
- [[ScanNet](http://www.scan-net.org/)] Richly-annotated 3D Reconstructions of Indoor Scenes. 
- [[Stanford 3D](https://graphics.stanford.edu/data/3Dscanrep/)] The Stanford 3D Scanning Repository. 
- [[Princeton Shape Benchmark](http://shape.cs.princeton.edu/benchmark/)] The Princeton Shape Benchmark.
- [[Large-Scale Point Cloud Classification Benchmark(ETH)](http://www.semantic3d.net/)] This benchmark closes the gap and provides a large labelled 3D point cloud data set of natural scenes with over 4 billion points in total. 
- [[PASCAL3D+](http://cvgl.stanford.edu/projects/pascal3d.html)] Beyond PASCAL: A Benchmark for 3D Object Detection in the Wild. 
- [[nuScenes](https://d3u7q4379vrm7e.cloudfront.net/object-detection)] The nuScenes dataset is a large-scale autonomous driving dataset.
- [[3D Match](http://3dmatch.cs.princeton.edu/)] Keypoint Matching Benchmark, Geometric Registration Benchmark, RGB-D Reconstruction Datasets. 
- [[SemanticKITTI](http://semantic-kitti.org)] Sequential Semantic Segmentation, 28 classes, for autonomous driving. All sequences of KITTI odometry labeled. [[ICCV 2019 paper](https://arxiv.org/abs/1904.01416)] 
- [[The Waymo Open Dataset](https://waymo.com/open/)] The Waymo Open Dataset is comprised of high resolution sensor data collected by Waymo self-driving cars in a wide variety of conditions. 
- [[Oxford Robotcar](https://robotcar-dataset.robots.ox.ac.uk/)] The dataset captures many different combinations of weather, traffic and pedestrians. 
---
## References

- https://github.com/timzhang642/3D-Machine-Learning
- https://github.com/QingyongHu/SoTA-Point-Cloud
- https://github.com/Yochengliu/awesome-point-cloud-analysis
## Updates
* 17/08/2020: adding view-based method and datasets
